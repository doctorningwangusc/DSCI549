{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f2dd8d0",
   "metadata": {},
   "source": [
    "\n",
    "# HW4\n",
    "\n",
    "**Scope:** Warm‑up → K‑Means → choosing *k* → DBSCAN → Hierarchical → compare.  \n",
    "**Dataset:** Iris (built‑in).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9eb627",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (6,4)\n",
    "np.random.seed(0)\n",
    "print(\"✅ Environment ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96814bbc",
   "metadata": {},
   "source": [
    "\n",
    "## Part 1: Warm‑up: Load, Scale, and Inspect \n",
    "\n",
    "**Why scaling?** Distance‑based algorithms (K‑Means, DBSCAN with Euclidean metric, Ward’s hierarchical) can be dominated by features with larger numeric ranges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20482b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Iris\n",
    "iris = load_iris(as_frame=True)\n",
    "X_df = iris.data.copy()     # DataFrame for readability\n",
    "y = iris.target.values      # labels for optional ARI\n",
    "\n",
    "display(X_df.describe())\n",
    "print(\"Shape:\", X_df.shape)\n",
    "print(\"Features:\", list(X_df.columns))\n",
    "\n",
    "# Standardize for algorithms\n",
    "scaler = StandardScaler().fit(X_df.values)\n",
    "X = scaler.transform(X_df.values)\n",
    "\n",
    "# We'll use two raw features for simple 2D plots (no PCA)\n",
    "feat_x, feat_y = \"petal length (cm)\", \"petal width (cm)\"\n",
    "ix, iy = list(X_df.columns).index(feat_x), list(X_df.columns).index(feat_y)\n",
    "\n",
    "# Quick 2D scatter in raw (unscaled) coordinates for intuition\n",
    "plt.scatter(X_df.iloc[:, ix], X_df.iloc[:, iy], s=20)\n",
    "plt.xlabel(feat_x); plt.ylabel(feat_y); plt.title(\"Raw feature view (unscaled)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d14100",
   "metadata": {},
   "source": [
    "\n",
    "**Q1:** Explain why scaling features can change the result of distance‑based clustering. Give one concrete failure mode if you **skip** scaling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea35fef",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2: K‑Means (k = 3)\n",
    "\n",
    "- **K‑Means** groups points by minimizing within‑cluster squared distances.  \n",
    "- **Inertia**: sum of squared distances to the assigned centroid (↓ is better, but always decreases as k↑).  \n",
    "- **Silhouette**: (b − a) / max(a, b) where *a* is mean intra‑cluster distance, *b* is mean distance to nearest other cluster. Ranges \\[-1, 1\\]; higher is better. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e792ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "km3 = KMeans(n_clusters=3, n_init=10, random_state=0).fit(X)\n",
    "labels3 = km3.labels_\n",
    "sil3 = silhouette_score(X, labels3)\n",
    "\n",
    "# Visualize using two raw features; color by K-Means labels\n",
    "plt.scatter(X_df.iloc[:, ix], X_df.iloc[:, iy], c=labels3, s=20)\n",
    "plt.xlabel(feat_x); plt.ylabel(feat_y)\n",
    "plt.title(f\"K-Means (k=3) on scaled data — silhouette={sil3:.3f}\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Inertia (k=3): {km3.inertia_:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e307a026",
   "metadata": {},
   "source": [
    "\n",
    "**Q2:** What does a **high** silhouette imply about cohesion and separation? Why might the 2D scatter above look clean while the silhouette is mediocre?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae20804c",
   "metadata": {},
   "source": [
    "\n",
    "## Part 3: Choosing the Number of Clusters *k* (Elbow + Silhouette)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db90ece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ks = range(2, 7)\n",
    "inertias, sils = [], []\n",
    "\n",
    "for k in ks:\n",
    "    km = KMeans(n_clusters=k, n_init=10, random_state=0).fit(X)\n",
    "    labels = km.labels_\n",
    "    inertias.append(km.inertia_)\n",
    "    sils.append(silhouette_score(X, labels))\n",
    "\n",
    "# Plot elbow\n",
    "plt.plot(list(ks), inertias, marker='o')\n",
    "plt.xlabel(\"k\"); plt.ylabel(\"Inertia (lower is better)\")\n",
    "plt.title(\"Elbow: Inertia vs k\")\n",
    "plt.show()\n",
    "\n",
    "# Plot silhouette\n",
    "plt.plot(list(ks), sils, marker='o')\n",
    "plt.xlabel(\"k\"); plt.ylabel(\"Silhouette (higher is better)\")\n",
    "plt.title(\"Silhouette vs k\")\n",
    "plt.show()\n",
    "\n",
    "print(\"k  | inertia     | silhouette\")\n",
    "for k, inn, si in zip(ks, inertias, sils):\n",
    "    print(f\"{k:<3}| {inn:<11.2f}| {si:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3328876f",
   "metadata": {},
   "source": [
    "\n",
    "**Q3:** Pick a **k** you find reasonable and justify it using both plots. If your choice differs from the highest‑silhouette value, explain why.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c2f582",
   "metadata": {},
   "source": [
    "\n",
    "## Part 4: Density‑Based Clustering with DBSCAN \n",
    "\n",
    "**DBSCAN basics:**  \n",
    "- **eps**: neighborhood radius; **min_samples**: minimum points to form a dense region.  \n",
    "- Labels: core clusters get 0..C−1; **noise points** are labeled **−1**.  \n",
    "- Pros: finds **arbitrary shapes** and flags noise; no need to choose *k*.  \n",
    "- Cons: sensitive to **scaling** and parameter choice; one global density may struggle when clusters differ in density.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e6953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_dbscan_grid(X, eps_list, ms_list):\n",
    "    rows = []\n",
    "    for e in eps_list:\n",
    "        for m in ms_list:\n",
    "            db = DBSCAN(eps=e, min_samples=m).fit(X)\n",
    "            labels = db.labels_\n",
    "            n_noise = int(np.sum(labels == -1))\n",
    "            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "            sil = np.nan\n",
    "            if n_clusters > 1:\n",
    "                try:\n",
    "                    from sklearn.metrics import silhouette_score\n",
    "                    sil = silhouette_score(X, labels)\n",
    "                except Exception:\n",
    "                    sil = np.nan\n",
    "            rows.append({\"eps\": e, \"min_samples\": m, \"n_clusters\": n_clusters, \"n_noise\": n_noise, \"silhouette\": sil})\n",
    "    return pd.DataFrame(rows).sort_values([\"n_clusters\",\"silhouette\"], ascending=[False, False]).reset_index(drop=True)\n",
    "\n",
    "eps_list = [0.2, 0.3, 0.4, 0.5]\n",
    "ms_list  = [3, 5, 8]\n",
    "\n",
    "grid = run_dbscan_grid(X, eps_list, ms_list)\n",
    "display(grid.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abe47f6",
   "metadata": {},
   "source": [
    "\n",
    "Pick **two** promising configurations from the table to visualize below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e7a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "configs = [\n",
    "    {\"eps\": 0.3, \"min_samples\": 5},\n",
    "    {\"eps\": 0.4, \"min_samples\": 5},\n",
    "]\n",
    "\n",
    "for cfg in configs:\n",
    "    db = DBSCAN(eps=cfg[\"eps\"], min_samples=cfg[\"min_samples\"]).fit(X)\n",
    "    labels = db.labels_\n",
    "    plt.scatter(X_df.iloc[:, ix], X_df.iloc[:, iy], c=labels, s=20)\n",
    "    plt.xlabel(feat_x); plt.ylabel(feat_y)\n",
    "    plt.title(f\"DBSCAN eps={cfg['eps']}, min_samples={cfg['min_samples']}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb101ca6",
   "metadata": {},
   "source": [
    "\n",
    "**Q4:** How did changing **eps** and **min_samples** affect the **number of clusters** and **noise points**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cff27a",
   "metadata": {},
   "source": [
    "\n",
    "## Part 5: Hierarchical Clustering + Dendrogram\n",
    "\n",
    " \n",
    "- **Agglomerative clustering (Ward linkage)** starts with each point as its own cluster and merges pairs that minimally increase within‑cluster variance.  \n",
    "- A **dendrogram** visualizes merge distances; a **horizontal cut** corresponds to choosing a number of clusters.  \n",
    "- Like K‑Means, Ward linkage uses Euclidean geometry and benefits from scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34fc8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Subsample for dendrogram readability\n",
    "subset_n = 120\n",
    "X_sub = X[:subset_n]\n",
    "\n",
    "# Linkage matrix with Ward's method\n",
    "Z_link = linkage(X_sub, method='ward')\n",
    "\n",
    "# Dendrogram (truncated display)\n",
    "plt.figure(figsize=(8, 4))\n",
    "dendrogram(Z_link, truncate_mode='lastp', p=20, leaf_rotation=30)\n",
    "plt.title(\"Hierarchical clustering dendrogram (truncated)\")\n",
    "plt.xlabel(\"Merged cluster index\"); plt.ylabel(\"Merge distance\")\n",
    "plt.show()\n",
    "\n",
    "# Choose a cut (set number of clusters) and fit Agglomerative on the full set\n",
    "n_clusters = 3  # ← adjust after inspecting dendrogram if desired\n",
    "agg = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
    "labels_agg = agg.fit_predict(X)\n",
    "\n",
    "# Visualize on raw feature axes\n",
    "plt.scatter(X_df.iloc[:, ix], X_df.iloc[:, iy], c=labels_agg, s=20)\n",
    "plt.xlabel(feat_x); plt.ylabel(feat_y)\n",
    "plt.title(f\"Agglomerative (Ward) — n_clusters={n_clusters}\")\n",
    "plt.show()\n",
    "\n",
    "# Optional silhouette for the chosen cut\n",
    "if n_clusters > 1:\n",
    "    sil_agg = silhouette_score(X, labels_agg)\n",
    "    print(f\"Silhouette (Agglomerative, n={n_clusters}): {sil_agg:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b614b709",
   "metadata": {},
   "source": [
    "\n",
    "**Q5:** Based on the dendrogram, explain how you chose the cut (number of clusters). Compare this hierarchical result to your best K‑Means result.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
